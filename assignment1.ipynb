{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rn597959/Java2/blob/master/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR6AEXpLdqyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e286b81d-9ea9-47d2-cbe0-35d5f20e2ab6"
      },
      "source": [
        "import numpy as np\n",
        "def get_gradients (x , y , w , b , l =0.01):\n",
        "    grad_w=0\n",
        "    grad_b=0\n",
        "    for i in range(len(x)):\n",
        "      grad_w = grad_w + x[i]*(w[i]*x[i]+b-y[i])\n",
        "      grad_b = grad_b + (w[i]*x[i]+b-y[i])\n",
        "    grad_w = l * (1/len(x)) * grad_w\n",
        "    grad_b = l * (1/len(x)) * grad_b\n",
        "    return grad_w,grad_b\n",
        "  \n",
        "  \n",
        "get_gradients (x=[1,2,3,4,5] , y=[1,2,3,4,5] , w=[1,2,3,4,5] , b=2 , l =0.01)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4, 0.1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFfaB2a8IGsW",
        "colab_type": "text"
      },
      "source": [
        "# **Question2**\n",
        "\n",
        "\n",
        " **Background**\n",
        "\n",
        "Before figuring this question, we need to know the purpose of machine learning is to find a appropriated algorithm to analysis the data, with this view, after getting the tagged data, specifically under the supervised algorithm, how to use the data as training/testing and predicting is the first issue for analyst to consider about.\n",
        "\n",
        "\n",
        "**The method for getting the training and testing data**\n",
        "\n",
        "First way is to use the function sklearn.model_selection.train_test_split(*arrays, **options) to split the data into two parts. For example, 50% of the data for training set and 50% of the data for testing set. The advantage for this method is easy to implement. The disadvantage is the accuracy cannot be guaranteed, since there is not enough training set to build the model or the testing set is not enough to test the model.\n",
        "\n",
        "Second way is to use the k-fold cross validation method, for example, a 10-fold cross validation will split the data into 10 parts equally, we will have 10 times for training and testing. For each fold, 90% of data will be used in training stage, 10% will be used for testing/predicting stage. \n",
        "\n",
        "**Confusion matrix**\n",
        "\n",
        "In order to evaluate the the result of prediction for the algorithm, such as SVM, Random Forest, Linear Regression and Neural Network, we have to calculate and show the difference between prediction value and target value, this can be done with a confusion matrix which is a matrix with the cells which represent the counts of given corrected input with predicted result.\n",
        "\n",
        "**The solution for the question**\n",
        "\n",
        "For example, if we have a dataset which have height(X1) and weight(X2) in order to get the person's gender(target Y), and there are 100 records. When applying the 10 folder cross validation. Since we will have 10 times for training/prediction, and each iteration has 0.9*100 for training and 0.1*100 for testing, we can get 10 confusion matrix, if we add the 10 matrix together, we can get one final matrix.\n",
        "\n",
        "The problem need to be solved with the above method is that how to add matrix, for example, in the first iteration of 10 folder CV, the matrix could be 1*1 only, if the target column in testing data only has one type of gender and all of the prediction is correct. The second matrix could have two rows or two columns even the input target data is one, but the predict result has two types.Therefore, we cannot simply add 10 matrix together, since the dimension is not equal. \n",
        "\n",
        "In my way to doing this, we can add number of the target of all 10 test set together, which includes all the dataset, and also count all responds prediction result for all 10 test set and add together. Based on these target and prediction data to get the confusion matrix. Getting the confusion matrix by using these two functions: cross_val_predict and confusion_matrix. The parameter of confusion_matrix is the correct data and the prediction data, and the prediction data is the output of cross_val_predict.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH5yf2fKwSrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcwBSLorwTAm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}